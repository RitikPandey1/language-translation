{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense\n",
    "import numpy as np\n",
    "\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "latent_dim = 256\n",
    "num_samples = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_txt = []\n",
    "otp_txt = []\n",
    "inp_chr = set()\n",
    "otp_chr  = set()\n",
    "\n",
    "with open('./fra_dataset.txt',encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "\n",
    "for line in lines[:num_samples]:\n",
    "    inp , otp , _ = line.split(\"\\t\")\n",
    "    inp_txt.append(inp)\n",
    "    otp = '\\t'+ otp + '\\n'\n",
    "    otp_txt.append(otp)\n",
    "    for char in inp:\n",
    "        inp_chr.add(char)\n",
    "    for char in otp :\n",
    "        otp_chr.add(char)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['\\t', '\\n', ' ', '!', '%', '&', \"'\", '(', ')', ',', '-', '.', '0', '1', '2', '3', '5', '8', '9', ':', '?', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'Y', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z', '\\xa0', '«', '»', 'À', 'Ç', 'É', 'Ê', 'à', 'â', 'ç', 'è', 'é', 'ê', 'î', 'ï', 'ô', 'ù', 'û', 'œ', '\\u2009', '’', '\\u202f']\n",
      "Total samples :  10000\n",
      "Total encoder tokens :  71\n",
      "Total decoder tokens :  92\n",
      "Maximum input sequence length :  15\n",
      "Maximum output sequence length :  59\n"
     ]
    }
   ],
   "source": [
    "inp_chr  = sorted(list(inp_chr))\n",
    "otp_chr  = sorted(list(otp_chr))\n",
    "enc_len = len(inp_chr)\n",
    "dec_len = len(otp_chr)\n",
    "enc_seq_len = max([len(txt) for txt in inp_txt])\n",
    "dec_seq_len = max([len(txt) for txt in otp_txt])\n",
    "print(otp_chr)\n",
    "print(\"Total samples : \", len(inp_txt))\n",
    "print(\"Total encoder tokens : \",enc_len)\n",
    "print(\"Total decoder tokens : \",dec_len)\n",
    "print(\"Maximum input sequence length : \", enc_seq_len)\n",
    "print(\"Maximum output sequence length : \", dec_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_token_id = dict( [(char,i) for i,char in enumerate(inp_chr)])\n",
    "otp_token_id = dict( [(char,i) for i,char in enumerate(otp_chr)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inp_data = np.zeros((len(inp_txt),enc_seq_len,enc_len), dtype=\"float32\")\n",
    "dec_inp_data = np.zeros((len(otp_txt),dec_seq_len, dec_len), dtype=\"float32\")\n",
    "dec_target_data = np.zeros((len(otp_txt),dec_seq_len, dec_len), dtype=\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 15, 71)\n",
      "(10000, 59, 92)\n",
      "(10000, 59, 92)\n"
     ]
    }
   ],
   "source": [
    "# one hot encoding\n",
    "for i,(i_t,o_t) in enumerate(zip(inp_txt,otp_txt)):\n",
    "    for t,char in enumerate(i_t):\n",
    "        enc_inp_data[i,t,inp_token_id[char]] = 1\n",
    "    enc_inp_data[i,t+1:,inp_token_id[' ']] = 1\n",
    "    \n",
    "    for t, char in enumerate(o_t):\n",
    "        dec_inp_data[i,t,otp_token_id[char]] = 1\n",
    "        if t>0:\n",
    "            dec_target_data[i,t-1,otp_token_id[char]] = 1\n",
    "    dec_inp_data[i,t+1:,otp_token_id[' ']] = 1\n",
    "    dec_target_data[i,t:,otp_token_id[char]] = 1\n",
    "\n",
    "print(enc_inp_data.shape)\n",
    "print(dec_inp_data.shape)\n",
    "print(dec_target_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder\n",
    "enc_inps = Input(shape=(None,enc_len))\n",
    "encoder = LSTM(latent_dim,return_state=True)\n",
    "# only consider state of encoder h,c ignore otps\n",
    "enc_otps, state_h, state_c = encoder(enc_inps)\n",
    "\n",
    "#decoder\n",
    "dec_inps = Input(shape=(None,dec_len))\n",
    "decoder = LSTM(latent_dim,return_sequences=True, return_state=True)\n",
    "dec_otps , _ , _ = decoder(dec_inps,initial_state=[state_h,state_c])\n",
    "\n",
    "dec_otps = Dense(dec_len,activation='softmax')(dec_otps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 71)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 92)]   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     [(None, 256), (None, 335872      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   [(None, None, 256),  357376      input_2[0][0]                    \n",
      "                                                                 lstm[0][1]                       \n",
      "                                                                 lstm[0][2]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, None, 92)     23644       lstm_1[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 716,892\n",
      "Trainable params: 716,892\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model  = Model([enc_inps,dec_inps],dec_otps)\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "125/125 [==============================] - 14s 51ms/step - loss: 1.1322 - accuracy: 0.7360 - val_loss: 1.0339 - val_accuracy: 0.7146\n",
      "Epoch 2/100\n",
      "125/125 [==============================] - 6s 45ms/step - loss: 0.8188 - accuracy: 0.7793 - val_loss: 0.8216 - val_accuracy: 0.7741\n",
      "Epoch 3/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.6498 - accuracy: 0.8168 - val_loss: 0.6806 - val_accuracy: 0.8030\n",
      "Epoch 4/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.5660 - accuracy: 0.8358 - val_loss: 0.6191 - val_accuracy: 0.8211\n",
      "Epoch 5/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.5182 - accuracy: 0.8488 - val_loss: 0.5802 - val_accuracy: 0.8323\n",
      "Epoch 6/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.4830 - accuracy: 0.8583 - val_loss: 0.5494 - val_accuracy: 0.8400\n",
      "Epoch 7/100\n",
      "125/125 [==============================] - 6s 45ms/step - loss: 0.4547 - accuracy: 0.8653 - val_loss: 0.5304 - val_accuracy: 0.8441\n",
      "Epoch 8/100\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.4321 - accuracy: 0.8714 - val_loss: 0.5145 - val_accuracy: 0.8487\n",
      "Epoch 9/100\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.4116 - accuracy: 0.8774 - val_loss: 0.5000 - val_accuracy: 0.8541\n",
      "Epoch 10/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.3935 - accuracy: 0.8826 - val_loss: 0.4881 - val_accuracy: 0.8557\n",
      "Epoch 11/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.3766 - accuracy: 0.8872 - val_loss: 0.4873 - val_accuracy: 0.8571\n",
      "Epoch 12/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.3619 - accuracy: 0.8914 - val_loss: 0.4711 - val_accuracy: 0.8615\n",
      "Epoch 13/100\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.3473 - accuracy: 0.8956 - val_loss: 0.4647 - val_accuracy: 0.8635\n",
      "Epoch 14/100\n",
      "125/125 [==============================] - 6s 44ms/step - loss: 0.3343 - accuracy: 0.8994 - val_loss: 0.4575 - val_accuracy: 0.8668\n",
      "Epoch 15/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.3220 - accuracy: 0.9028 - val_loss: 0.4538 - val_accuracy: 0.8677\n",
      "Epoch 16/100\n",
      "125/125 [==============================] - 5s 44ms/step - loss: 0.3100 - accuracy: 0.9068 - val_loss: 0.4595 - val_accuracy: 0.8664\n",
      "Epoch 17/100\n",
      "125/125 [==============================] - 5s 44ms/step - loss: 0.2989 - accuracy: 0.9098 - val_loss: 0.4493 - val_accuracy: 0.8705\n",
      "Epoch 18/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2882 - accuracy: 0.9132 - val_loss: 0.4448 - val_accuracy: 0.8729\n",
      "Epoch 19/100\n",
      "125/125 [==============================] - 5s 43ms/step - loss: 0.2779 - accuracy: 0.9163 - val_loss: 0.4474 - val_accuracy: 0.8732\n",
      "Epoch 20/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.2682 - accuracy: 0.9191 - val_loss: 0.4473 - val_accuracy: 0.8736\n",
      "Epoch 21/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.2589 - accuracy: 0.9216 - val_loss: 0.4489 - val_accuracy: 0.8733\n",
      "Epoch 22/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.2499 - accuracy: 0.9245 - val_loss: 0.4468 - val_accuracy: 0.8741\n",
      "Epoch 23/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.2415 - accuracy: 0.9270 - val_loss: 0.4504 - val_accuracy: 0.8751\n",
      "Epoch 24/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.2337 - accuracy: 0.9289 - val_loss: 0.4531 - val_accuracy: 0.8743\n",
      "Epoch 25/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.2257 - accuracy: 0.9317 - val_loss: 0.4548 - val_accuracy: 0.8746\n",
      "Epoch 26/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.2182 - accuracy: 0.9337 - val_loss: 0.4613 - val_accuracy: 0.8736\n",
      "Epoch 27/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.2112 - accuracy: 0.9358 - val_loss: 0.4575 - val_accuracy: 0.8750\n",
      "Epoch 28/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.2045 - accuracy: 0.9374 - val_loss: 0.4615 - val_accuracy: 0.8749\n",
      "Epoch 29/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1976 - accuracy: 0.9397 - val_loss: 0.4652 - val_accuracy: 0.8746\n",
      "Epoch 30/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1916 - accuracy: 0.9418 - val_loss: 0.4653 - val_accuracy: 0.8757\n",
      "Epoch 31/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.1858 - accuracy: 0.9432 - val_loss: 0.4676 - val_accuracy: 0.8759\n",
      "Epoch 32/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1798 - accuracy: 0.9451 - val_loss: 0.4737 - val_accuracy: 0.8755\n",
      "Epoch 33/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.1744 - accuracy: 0.9466 - val_loss: 0.4795 - val_accuracy: 0.8753\n",
      "Epoch 34/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1690 - accuracy: 0.9485 - val_loss: 0.4886 - val_accuracy: 0.8744\n",
      "Epoch 35/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1639 - accuracy: 0.9498 - val_loss: 0.4910 - val_accuracy: 0.8750\n",
      "Epoch 36/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1586 - accuracy: 0.9509 - val_loss: 0.4956 - val_accuracy: 0.8747\n",
      "Epoch 37/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1546 - accuracy: 0.9523 - val_loss: 0.5018 - val_accuracy: 0.8749\n",
      "Epoch 38/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1498 - accuracy: 0.9542 - val_loss: 0.5068 - val_accuracy: 0.8741\n",
      "Epoch 39/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1454 - accuracy: 0.9553 - val_loss: 0.5114 - val_accuracy: 0.8742\n",
      "Epoch 40/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1415 - accuracy: 0.9564 - val_loss: 0.5088 - val_accuracy: 0.8744\n",
      "Epoch 41/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1375 - accuracy: 0.9576 - val_loss: 0.5206 - val_accuracy: 0.8743\n",
      "Epoch 42/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1338 - accuracy: 0.9586 - val_loss: 0.5252 - val_accuracy: 0.8746\n",
      "Epoch 43/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1302 - accuracy: 0.9597 - val_loss: 0.5277 - val_accuracy: 0.8744\n",
      "Epoch 44/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1267 - accuracy: 0.9609 - val_loss: 0.5380 - val_accuracy: 0.8741\n",
      "Epoch 45/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.1232 - accuracy: 0.9617 - val_loss: 0.5427 - val_accuracy: 0.8732\n",
      "Epoch 46/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1201 - accuracy: 0.9626 - val_loss: 0.5431 - val_accuracy: 0.8749\n",
      "Epoch 47/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1170 - accuracy: 0.9635 - val_loss: 0.5505 - val_accuracy: 0.8742\n",
      "Epoch 48/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1139 - accuracy: 0.9644 - val_loss: 0.5571 - val_accuracy: 0.8725\n",
      "Epoch 49/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1113 - accuracy: 0.9653 - val_loss: 0.5559 - val_accuracy: 0.8738\n",
      "Epoch 50/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1084 - accuracy: 0.9661 - val_loss: 0.5668 - val_accuracy: 0.8735\n",
      "Epoch 51/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1057 - accuracy: 0.9672 - val_loss: 0.5719 - val_accuracy: 0.8732\n",
      "Epoch 52/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1032 - accuracy: 0.9676 - val_loss: 0.5755 - val_accuracy: 0.8733\n",
      "Epoch 53/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.1006 - accuracy: 0.9682 - val_loss: 0.5825 - val_accuracy: 0.8724\n",
      "Epoch 54/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0982 - accuracy: 0.9691 - val_loss: 0.5906 - val_accuracy: 0.8728\n",
      "Epoch 55/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0962 - accuracy: 0.9695 - val_loss: 0.5936 - val_accuracy: 0.8732\n",
      "Epoch 56/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0939 - accuracy: 0.9701 - val_loss: 0.5963 - val_accuracy: 0.8729\n",
      "Epoch 57/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0919 - accuracy: 0.9708 - val_loss: 0.5974 - val_accuracy: 0.8736\n",
      "Epoch 58/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0898 - accuracy: 0.9713 - val_loss: 0.6083 - val_accuracy: 0.8725\n",
      "Epoch 59/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0877 - accuracy: 0.9721 - val_loss: 0.6117 - val_accuracy: 0.8726\n",
      "Epoch 60/100\n",
      "125/125 [==============================] - 6s 46ms/step - loss: 0.0859 - accuracy: 0.9724 - val_loss: 0.6170 - val_accuracy: 0.8728\n",
      "Epoch 61/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0837 - accuracy: 0.9729 - val_loss: 0.6219 - val_accuracy: 0.8719\n",
      "Epoch 62/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0819 - accuracy: 0.9737 - val_loss: 0.6242 - val_accuracy: 0.8724\n",
      "Epoch 63/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0800 - accuracy: 0.9742 - val_loss: 0.6303 - val_accuracy: 0.8726\n",
      "Epoch 64/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0786 - accuracy: 0.9748 - val_loss: 0.6361 - val_accuracy: 0.8732\n",
      "Epoch 65/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0770 - accuracy: 0.9751 - val_loss: 0.6394 - val_accuracy: 0.8721\n",
      "Epoch 66/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0754 - accuracy: 0.9754 - val_loss: 0.6400 - val_accuracy: 0.8723\n",
      "Epoch 67/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0740 - accuracy: 0.9761 - val_loss: 0.6437 - val_accuracy: 0.8726\n",
      "Epoch 68/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0720 - accuracy: 0.9764 - val_loss: 0.6455 - val_accuracy: 0.8723\n",
      "Epoch 69/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0711 - accuracy: 0.9767 - val_loss: 0.6533 - val_accuracy: 0.8721\n",
      "Epoch 70/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0693 - accuracy: 0.9772 - val_loss: 0.6550 - val_accuracy: 0.8721\n",
      "Epoch 71/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0682 - accuracy: 0.9775 - val_loss: 0.6608 - val_accuracy: 0.8720\n",
      "Epoch 72/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0666 - accuracy: 0.9781 - val_loss: 0.6660 - val_accuracy: 0.8724\n",
      "Epoch 73/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0660 - accuracy: 0.9781 - val_loss: 0.6667 - val_accuracy: 0.8727\n",
      "Epoch 74/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0646 - accuracy: 0.9784 - val_loss: 0.6820 - val_accuracy: 0.8713\n",
      "Epoch 75/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0629 - accuracy: 0.9789 - val_loss: 0.6766 - val_accuracy: 0.8721\n",
      "Epoch 76/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0621 - accuracy: 0.9794 - val_loss: 0.6822 - val_accuracy: 0.8727\n",
      "Epoch 77/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0611 - accuracy: 0.9794 - val_loss: 0.6850 - val_accuracy: 0.8726\n",
      "Epoch 78/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0594 - accuracy: 0.9799 - val_loss: 0.6873 - val_accuracy: 0.8716\n",
      "Epoch 79/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0593 - accuracy: 0.9797 - val_loss: 0.6874 - val_accuracy: 0.8723\n",
      "Epoch 80/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0582 - accuracy: 0.9802 - val_loss: 0.6933 - val_accuracy: 0.8718\n",
      "Epoch 81/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0570 - accuracy: 0.9807 - val_loss: 0.7039 - val_accuracy: 0.8708\n",
      "Epoch 82/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0557 - accuracy: 0.9810 - val_loss: 0.7010 - val_accuracy: 0.8712\n",
      "Epoch 83/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0553 - accuracy: 0.9811 - val_loss: 0.7093 - val_accuracy: 0.8708\n",
      "Epoch 84/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0539 - accuracy: 0.9815 - val_loss: 0.7101 - val_accuracy: 0.8714\n",
      "Epoch 85/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0534 - accuracy: 0.9816 - val_loss: 0.7144 - val_accuracy: 0.8714\n",
      "Epoch 86/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0528 - accuracy: 0.9818 - val_loss: 0.7131 - val_accuracy: 0.8722\n",
      "Epoch 87/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0522 - accuracy: 0.9818 - val_loss: 0.7266 - val_accuracy: 0.8709\n",
      "Epoch 88/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0512 - accuracy: 0.9820 - val_loss: 0.7231 - val_accuracy: 0.8710\n",
      "Epoch 89/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0504 - accuracy: 0.9825 - val_loss: 0.7276 - val_accuracy: 0.8707\n",
      "Epoch 90/100\n",
      "125/125 [==============================] - 6s 48ms/step - loss: 0.0497 - accuracy: 0.9828 - val_loss: 0.7268 - val_accuracy: 0.8724\n",
      "Epoch 91/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0490 - accuracy: 0.9830 - val_loss: 0.7346 - val_accuracy: 0.8703\n",
      "Epoch 92/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0483 - accuracy: 0.9830 - val_loss: 0.7417 - val_accuracy: 0.8704\n",
      "Epoch 93/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0479 - accuracy: 0.9832 - val_loss: 0.7466 - val_accuracy: 0.8707\n",
      "Epoch 94/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0469 - accuracy: 0.9833 - val_loss: 0.7416 - val_accuracy: 0.8704\n",
      "Epoch 95/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0464 - accuracy: 0.9837 - val_loss: 0.7442 - val_accuracy: 0.8718\n",
      "Epoch 96/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0461 - accuracy: 0.9835 - val_loss: 0.7525 - val_accuracy: 0.8711\n",
      "Epoch 97/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0451 - accuracy: 0.9841 - val_loss: 0.7511 - val_accuracy: 0.8713\n",
      "Epoch 98/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0449 - accuracy: 0.9838 - val_loss: 0.7539 - val_accuracy: 0.8710\n",
      "Epoch 99/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0443 - accuracy: 0.9843 - val_loss: 0.7591 - val_accuracy: 0.8707\n",
      "Epoch 100/100\n",
      "125/125 [==============================] - 6s 47ms/step - loss: 0.0440 - accuracy: 0.9841 - val_loss: 0.7597 - val_accuracy: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d710ed5310>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([enc_inp_data,dec_inp_data],dec_target_data,batch_size = batch_size, epochs = epochs, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: s2s\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "model = keras.models.load_model(\"s2s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_inps = model.input[0] \n",
    "\n",
    "enc_otps , enc_state_h , enc_state_c = model.layers[2].output\n",
    "enc_states  = [enc_state_h,enc_state_c]\n",
    "enc_model = keras.Model(enc_inps,enc_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_inps = model.input[1]\n",
    "dec_state_inp_h = keras.Input(shape=(latent_dim,),name='input_5')\n",
    "dec_state_inp_c = keras.Input(shape=(latent_dim,),name='input_6')\n",
    "dec_states_inp = [dec_state_inp_h,dec_state_inp_c]\n",
    "\n",
    "dec_lstm = model.layers[3]\n",
    "\n",
    "dec_otps, dec_state_h , dec_state_c = dec_lstm(dec_inps,initial_state=dec_states_inp)\n",
    "\n",
    "dec_states = [dec_state_h,dec_state_c]\n",
    "\n",
    "dense = model.layers[4]\n",
    "dec_otps = dense(dec_otps)\n",
    "\n",
    "dec_model = keras.Model([dec_inps] + dec_states_inp , [dec_otps]+dec_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "rev_char_inp_id = dict((i,char) for char,i in inp_token_id.items())\n",
    "rev_char_tar_id = dict((i,char) for char,i in otp_token_id.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_seq(inp_seq):\n",
    "    states_val = enc_model.predict(inp_seq)\n",
    "\n",
    "    target_seq = np.zeros((1,1,dec_len))\n",
    "\n",
    "    target_seq[0,0,otp_token_id[\"\\t\"]] = 1.0\n",
    "\n",
    "    stop_cond = False\n",
    "    dec_sen = \"\"\n",
    "\n",
    "    while not stop_cond:\n",
    "        otp_tokens , h,c = dec_model.predict([target_seq]+states_val)\n",
    "\n",
    "        sample_token_id = np.argmax(otp_tokens[0,-1,:])\n",
    "        sample_char = rev_char_tar_id[sample_token_id]\n",
    "        dec_sen += sample_char\n",
    "\n",
    "        if sample_char ==\"\\n\" or len(dec_sen) > dec_seq_len :\n",
    "            stop_cond = True\n",
    "        target_seq = np.zeros((1,1,dec_len))\n",
    "        target_seq[0,0,sample_token_id] = 1.0\n",
    "\n",
    "        states_val = [h,c]\n",
    "    return dec_sen\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------\n",
      "Input sen :  Go.\n",
      "Decode sen :  Marche.\n",
      "\n",
      "----------------\n",
      "Input sen :  Go.\n",
      "Decode sen :  Marche.\n",
      "\n",
      "----------------\n",
      "Input sen :  Go.\n",
      "Decode sen :  Marche.\n",
      "\n",
      "----------------\n",
      "Input sen :  Hi.\n",
      "Decode sen :  Salut !\n",
      "\n",
      "----------------\n",
      "Input sen :  Hi.\n",
      "Decode sen :  Salut !\n",
      "\n",
      "----------------\n",
      "Input sen :  Run!\n",
      "Decode sen :  Fuyons !\n",
      "\n",
      "----------------\n",
      "Input sen :  Run!\n",
      "Decode sen :  Fuyons !\n",
      "\n",
      "----------------\n",
      "Input sen :  Run!\n",
      "Decode sen :  Fuyons !\n",
      "\n",
      "----------------\n",
      "Input sen :  Run!\n",
      "Decode sen :  Fuyons !\n",
      "\n",
      "----------------\n",
      "Input sen :  Run!\n",
      "Decode sen :  Fuyons !\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for id in range(10) :\n",
    "    inp_seq = enc_inp_data[id: id+1]\n",
    "    sen = decode_seq(inp_seq)\n",
    "    print(\"----------------\")\n",
    "    print(\"Input sen : \", inp_txt[id])\n",
    "    print(\"Decode sen : \", sen)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9973c6938f4aad7dcfd49854c1e0cc6453bbf87fb3680ba791d7b26d8dd01db7"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
